{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal files\n",
    "from historymatch import emulators\n",
    "from historymatch import sample\n",
    "from historymatch import historymatch\n",
    "from historymatch import plot\n",
    "from historymatch import utils\n",
    "\n",
    "\n",
    "# import external modules\n",
    "#import matplotlib.patches as patches\n",
    "#import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from scipy import stats\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "#from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "np.random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "with open(\"data/MassEval2016.dat\",'r') as infile:\n",
    "    Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11,12),\n",
    "              names=('N', 'Z', 'A', 'Element', 'Ebinding', 'E_unc'),\n",
    "              widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\n",
    "              header=64,\n",
    "              index_col=False)\n",
    "    \n",
    "# Extrapolated values are indicated by '#' in place of the decimal place, so\n",
    "# the Ebinding column won't be numeric. Coerce to float and drop these entries.\n",
    "Masses['Ebinding'] = pd.to_numeric(Masses['Ebinding'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "Masses['E_unc'] = pd.to_numeric(Masses['E_unc'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "# Convert from keV to MeV.\n",
    "Masses['Ebinding'] /= 1000\n",
    "Masses['E_unc'] /= 1000\n",
    "\n",
    "# Find the rows of the grouped DataFrame with the maximum binding energy.\n",
    "Masses_single = Masses.groupby('A').apply(lambda t: t[t.Ebinding==t.Ebinding.max()])\n",
    "\n",
    "A0_single = Masses_single['A'].to_numpy()\n",
    "Z0_single = Masses_single['Z'].to_numpy()\n",
    "N0_single = Masses_single['N'].to_numpy()\n",
    "Element_single = Masses_single['Element'].to_numpy()\n",
    "\n",
    "# convert energies per nucleon to energies\n",
    "Energies0_single = Masses_single['Ebinding'].to_numpy()\n",
    "\n",
    "Energies_unc0_single = Masses_single['E_unc'].to_numpy()\n",
    "\n",
    "# extract 3 nucleon around maximum\n",
    "Masses_triple = Masses.sort_values(['A','Ebinding'],ascending=False).groupby('A').head(3)\n",
    "\n",
    "A0_triple = Masses_triple['A'].to_numpy()\n",
    "Z0_triple = Masses_triple['Z'].to_numpy()\n",
    "N0_triple = Masses_triple['N'].to_numpy()\n",
    "Element_triple = Masses_triple['Element'].to_numpy()\n",
    "\n",
    "# convert energies per nucleon to energies\n",
    "Energies0_triple = Masses_triple['Ebinding'].to_numpy()\n",
    "\n",
    "Energies_unc0_triple = Masses_triple['E_unc'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space\n",
    "\n",
    "theta_0_bound = np.array([0, 40]).reshape(1,-1)\n",
    "theta_1_bound = np.array([-40, 10]).reshape(1,-1)\n",
    "theta_2_bound = np.array([-3, 3]).reshape(1,-1)\n",
    "theta_3_bound = np.array([-50, 0]).reshape(1,-1) # keep\n",
    "theta_4_bound = np.array([0, 40]).reshape(1,-1)\n",
    "\n",
    "parameter_bounds = np.concatenate((theta_0_bound, theta_1_bound, \\\n",
    "                                   theta_2_bound, theta_3_bound, theta_4_bound), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LiquidDropModel(params, A, Z, N):\n",
    "    \n",
    "    if len(params) == 4:\n",
    "        a1, a2, a3, a4 = params\n",
    "        EB = (a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0)) \\\n",
    "            + a4*((N-Z)**2)/A)\n",
    "        return EB/A\n",
    "    else:\n",
    "        a1, a2, a3, a4, a5 = params\n",
    "        EB = (a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0)) \\\n",
    "            + a4*((N-Z)**2)/A + a5*( (-1)**Z + (-1)**N )*(2*A**(-0.5)))\n",
    "        return EB/A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_error(_A):\n",
    "    \n",
    "    sigma_model = np.zeros(len(_A))     \n",
    "        \n",
    "    for i in range(len(_A)):\n",
    "        if _A[i] < 40:\n",
    "            sigma_model[i] = 0.09\n",
    "\n",
    "\n",
    "        elif _A[i] < 140:\n",
    "            sigma_model[i] = 0.05\n",
    "\n",
    "        elif _A[i] < 200:\n",
    "            sigma_model[i] = 0.04\n",
    "        else:\n",
    "            sigma_model[i] = 0.02\n",
    "            \n",
    "    return sigma_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define observational data for each wave\n",
    "\n",
    "# wave 1 - A < 40\n",
    "obs_data_wave1 = Energies0_single[10:30:2]\n",
    "A_wave1 = A0_single[10:30:2]\n",
    "Z_wave1 = Z0_single[10:30:2]\n",
    "N_wave1 = N0_single[10:30:2]\n",
    "variables_wave1 = np.concatenate((A_wave1.reshape(-1,1),Z_wave1.reshape(-1,1),\\\n",
    "                            N_wave1.reshape(-1,1)), axis=1)\n",
    "\n",
    "sigma_obs_wave1 = Energies_unc0_single[10:30:2]\n",
    "sigma_model_wave1 = create_model_error(A_wave1)\n",
    "\n",
    "\n",
    "# wave 2 - A < 140\n",
    "obs_data_wave2 = Energies0_single[10:130:3]\n",
    "A_wave2 = A0_single[10:130:3]\n",
    "Z_wave2 = Z0_single[10:130:3]\n",
    "N_wave2 = N0_single[10:130:3]\n",
    "variables_wave2 = np.concatenate((A_wave2.reshape(-1,1),Z_wave2.reshape(-1,1),\\\n",
    "                            N_wave2.reshape(-1,1)), axis=1)\n",
    "\n",
    "sigma_obs_wave2 = Energies_unc0_single[10:130:3]\n",
    "sigma_model_wave2 = create_model_error(A_wave2)\n",
    "\n",
    "\n",
    "# wave 3 - A < 200\n",
    "obs_data_wave3 = Energies0_single[10:190:3]\n",
    "A_wave3 = A0_single[10:190:3]\n",
    "Z_wave3 = Z0_single[10:190:3]\n",
    "N_wave3 = N0_single[10:190:3]\n",
    "variables_wave3 = np.concatenate((A_wave3.reshape(-1,1),Z_wave3.reshape(-1,1),\\\n",
    "                            N_wave3.reshape(-1,1)), axis=1)\n",
    "\n",
    "sigma_obs_wave3 = Energies_unc0_single[10:190:3]\n",
    "sigma_model_wave3 = create_model_error(A_wave3)\n",
    "\n",
    "\n",
    "# wave 4 - A > 200\n",
    "obs_data_wave4 = Energies0_single[10:-1:3]\n",
    "A_wave4 = A0_single[10:-1:3]\n",
    "Z_wave4 = Z0_single[10:-1:3]\n",
    "N_wave4 = N0_single[10:-1:3]\n",
    "variables_wave4 = np.concatenate((A_wave4.reshape(-1,1),Z_wave4.reshape(-1,1),\\\n",
    "                            N_wave4.reshape(-1,1)), axis=1)\n",
    "\n",
    "sigma_obs_wave4 = Energies_unc0_single[10:-1:3]\n",
    "sigma_model_wave4 = create_model_error(A_wave4)\n",
    "\n",
    "\n",
    "# wave 5 - introduce ap - all data such that 3 points around E minimum are captured\n",
    "obs_data_wave5 = np.flip(Energies0_triple)[30:-1:4]\n",
    "A_wave5 = np.flip(A0_triple)[30:-1:4]\n",
    "Z_wave5 = np.flip(Z0_triple)[30:-1:4]\n",
    "N_wave5 = np.flip(N0_triple)[30:-1:4]\n",
    "variables_wave5 = np.concatenate((A_wave5.reshape(-1,1),Z_wave5.reshape(-1,1),\\\n",
    "                            N_wave5.reshape(-1,1)), axis=1)\n",
    "\n",
    "sigma_obs_wave5 = np.flip(Energies_unc0_triple)[30:-1:4]\n",
    "sigma_model_wave5 = create_model_error(A_wave5)\n",
    "\n",
    "\n",
    "obs_data = [obs_data_wave1, obs_data_wave2, obs_data_wave3, obs_data_wave4, obs_data_wave5, obs_data_wave5]\n",
    "sigma_obs = [sigma_obs_wave1, sigma_obs_wave2, sigma_obs_wave3, sigma_obs_wave4, sigma_obs_wave5, sigma_obs_wave5]\n",
    "sigma_model = [sigma_model_wave1, sigma_model_wave2, sigma_model_wave3, sigma_model_wave4, sigma_model_wave5, sigma_model_wave5]\n",
    "\n",
    "variables = [variables_wave1, variables_wave2, variables_wave3, variables_wave4, variables_wave5, variables_wave5]\n",
    "\n",
    "sigma_method = [np.zeros_like(sigmas) for sigmas in sigma_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Matching - Separate Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "volshapes = ['gaussian', 'hypercube', 'hypercube_rot', 'ellipsoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwaves = 5\n",
    "ndim = 5\n",
    "nsamples = 1 * (10**6)\n",
    "volshape = 'ellipsoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise history matching class\n",
    "HM = historymatch.HistoryMatch(ndim, filename='result_dict', emulator='GP', volume_shape=volshape)\n",
    "# initialise results class\n",
    "Results = historymatch.Results('resultfile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ToyModel = historymatch.Simulator(HM)\n",
    "ToyModel.set_simulator(LiquidDropModel)\n",
    "\n",
    "HM.initialize_volume(parameter_bounds[:,0], parameter_bounds[:,1], ninactive=1, inactive_wave = 5, sigma_inactive=0.02)\n",
    "\n",
    "\n",
    "#wave1 = HM.run_wave(1, obs_data[0], sigma_obs[0], sigma_model[0], sigma_method[0], variables[0], nsamples=nsamples, ntraining=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HM.store_result(Results, wave=1, wave_results = wave1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_wave2 = HM.run_wave(2, obs_data[1], sigma_obs[1], sigma_model[1], sigma_method[1], variables[1], nsamples=nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_wave2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HM.store_result(Results, wave=2, wave_results = results_wave2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wave 2 results\n",
    "#plot.plotcorner(Results.samples_I[1], parameter_bounds, ndim-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Match - All Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running wave 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:38<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Non-Implausible Samples: 659\n",
      "Running wave 2\n",
      "ellipsoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:36<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Non-Implausible Samples: 5864\n",
      "Running wave 3\n",
      "ellipsoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [03:50<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Non-Implausible Samples: 158376\n",
      "Running wave 4\n",
      "ellipsoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 30/83 [01:54<03:21,  3.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e80751cbf5d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mHM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_observations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnwaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnwaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/historymatch.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nwaves, ntraining, nsamples, result_obj, emulate)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mnonimplausible_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_I\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                             self.run_wave(wave, observational_data, sigma_observational,\\\n\u001b[0m\u001b[1;32m    397\u001b[0m                                              sigma_model, sigma_method, wave_variables, nsamples, ntraining=None, emulate=emulate)\n\u001b[1;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnonimplausible_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_I\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/historymatch.py\u001b[0m in \u001b[0;36mrun_wave\u001b[0;34m(self, wave, observational_data, sigma_observational, sigma_model, sigma_method, wave_variables, nsamples, ntraining, emulate, Imax)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;31m# evaluate implausibility measure over parameter space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 implausibilities_all[i, output] = self.implausibility(mu[i], observational_data[output], sd[i]**2, sigma_observational[output]**2,\\\n\u001b[0m\u001b[1;32m    349\u001b[0m                                                                             sigma_method[output]**2, sigma_model[output]**2, sigma_inactive**2)\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/historymatch.py\u001b[0m in \u001b[0;36mimplausibility\u001b[0;34m(self, E, z_i, var_em, var_obs, var_method, var_model, var_inactive)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mE\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mz_i\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;34m/\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mvar_em\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar_obs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar_method\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar_model\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar_inactive\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialise all observational data and run multiple waves\n",
    "HM.set_observations(obs_data, variables=variables, sigma_obs=sigma_obs, sigma_model=sigma_model, sigma_method=sigma_method)\n",
    "\n",
    "results = HM.run(nwaves=nwaves, ntraining=100, nsamples=nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise history matching class\n",
    "HM2 = historymatch.HistoryMatch(ndim, filename='result_dict', emulator='GP', volume_shape='hypercube_rot')\n",
    "# initialise results class\n",
    "Results2 = historymatch.Results('resultfile')\n",
    "\n",
    "ToyModel2 = historymatch.Simulator(HM2)\n",
    "ToyModel2.set_simulator(LiquidDropModel)\n",
    "\n",
    "HM2.initialize_volume(parameter_bounds[:,0], parameter_bounds[:,1], ninactive=1, inactive_wave = 5, sigma_inactive=0.02)\n",
    "\n",
    "HM2.set_observations(obs_data, variables=variables, sigma_obs=sigma_obs, sigma_model=sigma_model, sigma_method=sigma_method)\n",
    "\n",
    "results_hc_rot = HM2.run(nwaves=nwaves, ntraining=100, nsamples=nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "ax.scatter(results_hc_rot.nonimplausible[0][:,0],results_hc_rot.nonimplausible[0][:,1], alpha=0.1, zorder=5, color='black')\n",
    "\n",
    "ax.scatter(results.samples_I[1][:,0],results.samples_I[1][:,1])\n",
    "ax.scatter(results_hc_rot.samples_I[1][:,0],results_hc_rot.samples_I[1][:,1])\n",
    "plt.axis('square')\n",
    "\n",
    "ax.set_xlim([0,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "ax.scatter(results_hc_rot.nonimplausible[0][:,0],results_hc_rot.nonimplausible[0][:,1], alpha=0.1, zorder=5, color='black')\n",
    "ax.scatter(results.nonimplausible[0][:,0],results.nonimplausible[0][:,1], alpha=0.1, zorder=5, color='red')\n",
    "\n",
    "#ax.scatter(results.samples_I[1][:,0],results.samples_I[1][:,1])\n",
    "#ax.scatter(results_hc_rot.samples_I[1][:,0],results_hc_rot.samples_I[1][:,1])\n",
    "plt.axis('square')\n",
    "\n",
    "ax.set_xlim([0,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcov = np.array([[3,2],[2,3]])\n",
    "_eigvals, eigvecs = np.linalg.eig(testcov)\n",
    "\n",
    "testpts = np.random.multivariate_normal([0,0], testcov,1000)\n",
    "R = eigvecs.T\n",
    "testpts2 = np.dot(testpts,R)\n",
    "plt.scatter(testpts[:,0], testpts[:,1])\n",
    "#plt.scatter(testpts2[:,0], testpts2[:,1])\n",
    "#plt.scatter(0,0)\n",
    "print(2*2*np.sqrt(_eigvals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance = np.cov(results_hc_rot.nonimplausible[0][:,:-1].T)\n",
    "\n",
    "_eigvals, eigvecs = np.linalg.eig(covariance)\n",
    "print(covariance)\n",
    "R = eigvecs.T                            # rotation matrix\n",
    "S = 2*np.eye(4)*np.sqrt(_eigvals)     # scaling matrix\n",
    "T = np.dot(S, np.linalg.inv(R))          # tranformation matrix\n",
    "\n",
    "print(S)\n",
    "scaled_samples = np.zeros((len(results_hc_rot.samples_I[1]),4))\n",
    "for i in range(len(results_hc_rot.samples_I[1])):\n",
    "    scaled_samples[i] = np.dot(R, results_hc_rot.samples_I[1][i,:4])\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "ax.scatter(results_hc_rot.samples_I[1][:,0],results_hc_rot.samples_I[1][:,1])\n",
    "#ax.scatter(scaled_samples[:,0],scaled_samples[:,1])\n",
    "plt.axis('square')\n",
    "\n",
    "#ax.set_xlim([0,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    \n",
    "    \n",
    "    # number of nonimplausible samples\n",
    "    print(hypercube_rot_nonimplausible[k].shape)\n",
    "    \n",
    "    # rotate to straight\n",
    "    covariance = np.cov(hypercube_rot_samples[k+1][:,:-1].T)\n",
    "    _eigvals, eigvecs = np.linalg.eigh(covariance)\n",
    "\n",
    "    R = eigvecs.T\n",
    "    nonimp_straight = hypercube_rot_samples[k+1][:,:-1].dot(np.linalg.inv(R))\n",
    "    if k < 4:\n",
    "        hc_rot_bounds = utils.locate_boundaries(nonimp_straight, 4)\n",
    "        hc_rot_volume = 1\n",
    "        initial_volume = 1\n",
    "        for i in range(4):\n",
    "            initial_volume *= np.abs(initial_parameter_bounds[i,1]-initial_parameter_bounds[i,0])\n",
    "            hc_rot_volume *= np.abs(hc_rot_bounds[i,1]-hc_rot_bounds[i,0]) \n",
    "    else:\n",
    "        hc_rot_bounds = utils.locate_boundaries(nonimp_straight, 5)\n",
    "        hc_rot_volume = 1\n",
    "        initial_volume = 1\n",
    "        for i in range(5):\n",
    "            initial_volume *= np.abs(initial_parameter_bounds[i,1]-initial_parameter_bounds[i,0])\n",
    "            hc_rot_volume *= np.abs(hc_rot_bounds[i,1]-hc_rot_bounds[i,0])\n",
    "    print(hc_rot_volume)\n",
    "    \n",
    "    print('Rotated Hypercube volume  : ' + str(100*np.prod(4*np.sqrt(_eigvals))/initial_volume) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
