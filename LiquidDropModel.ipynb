{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal files\n",
    "from historymatch import emulators\n",
    "from historymatch import sample\n",
    "from historymatch import historymatch\n",
    "from historymatch import plot\n",
    "from historymatch import utils\n",
    "\n",
    "\n",
    "# import external modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import pandas as pd\n",
    "#import importlib\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import sklearn.linear_model as skl\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "np.random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "with open(\"data/MassEval2016.dat\",'r') as infile:\n",
    "    Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11,12),\n",
    "              names=('N', 'Z', 'A', 'Element', 'Ebinding', 'E_unc'),\n",
    "              widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\n",
    "              header=64,\n",
    "              index_col=False)\n",
    "    \n",
    "# Extrapolated values are indicated by '#' in place of the decimal place, so\n",
    "# the Ebinding column won't be numeric. Coerce to float and drop these entries.\n",
    "Masses['Ebinding'] = pd.to_numeric(Masses['Ebinding'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "Masses['E_unc'] = pd.to_numeric(Masses['E_unc'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "# Convert from keV to MeV.\n",
    "Masses['Ebinding'] /= 1000\n",
    "Masses['E_unc'] /= 1000\n",
    "\n",
    "# Group the DataFrame by nucleon number, A.\n",
    "Masses = Masses.groupby('A')\n",
    "# Find the rows of the grouped DataFrame with the maximum binding energy.\n",
    "Masses = Masses.apply(lambda t: t[t.Ebinding==t.Ebinding.max()])\n",
    "\n",
    "A0 = Masses['A'].to_numpy()\n",
    "Z0 = Masses['Z'].to_numpy()\n",
    "N0 = Masses['N'].to_numpy()\n",
    "Element = Masses['Element'].to_numpy()\n",
    "Energies = Masses['Ebinding'].to_numpy()\n",
    "\n",
    "#Energies_unc = Masses['E_unc'].to_numpy()\n",
    "Energies_unc = Masses['E_unc'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space\n",
    "\n",
    "\n",
    "a0_lim = np.array([4,8]).reshape(1,-1)\n",
    "a1_lim = np.array([0, 1.1]).reshape(1,-1)\n",
    "a2_lim = np.array([-0.4, 0.1]).reshape(1,-1)\n",
    "a3_lim = np.array([-0.01, 0.015]).reshape(1,-1)\n",
    "a4_lim = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "a5_lim = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "\n",
    "#[ 5.73205069 -0.15849126  0.73057298  0.00661303  0.21505478  0.12058198]\n",
    "\n",
    "a_limits = np.concatenate((a0_lim, a1_lim, \\\n",
    "                            a2_lim, a3_lim, a4_lim, a5_lim), axis=0)\n",
    "\n",
    "theta_0_vals = np.linspace(a_limits[0,0], a_limits[0,1], 100)\n",
    "theta_1_vals = np.linspace(a_limits[1,0], a_limits[1,1], 100)\n",
    "theta_2_vals = np.linspace(a_limits[2,0], a_limits[2,1], 100)\n",
    "\n",
    "#theta_0_bound = np.array([4, 8]).reshape(1,-1)\n",
    "#theta_1_bound = np.array([-0.4, 0]).reshape(1,-1)\n",
    "#theta_2_bound = np.array([0.4, 0.7]).reshape(1,-1)\n",
    "#theta_3_bound = np.array([-0.005, 0.015]).reshape(1,-1) # keep\n",
    "#theta_4_bound = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "#theta_5_bound = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "\n",
    "\n",
    "theta_0_bound = np.array([0, 15]).reshape(1,-1)\n",
    "theta_1_bound = np.array([-2, 2]).reshape(1,-1)\n",
    "theta_2_bound = np.array([-2, 2]).reshape(1,-1)\n",
    "theta_3_bound = np.array([-0.1, 0.1]).reshape(1,-1) # keep\n",
    "theta_4_bound = np.array([-1, 1]).reshape(1,-1)\n",
    "theta_5_bound = np.array([-1, 1]).reshape(1,-1)\n",
    "\n",
    "\n",
    "parameter_bounds = np.concatenate((theta_0_bound, theta_1_bound, \\\n",
    "                                   theta_2_bound, theta_3_bound, theta_4_bound, theta_5_bound), axis=0)\n",
    "\n",
    "\n",
    "theta_vals = np.concatenate((theta_0_vals.reshape(1,-1), theta_1_vals.reshape(1,-1), theta_2_vals.reshape(1,-1)), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1325"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LiquidDropModel4d(a0, a1, a2, a3, A, Z, N):\n",
    "    \n",
    "    return a0 + a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0))\n",
    "\n",
    "def LiquidDropModel5d(a0, a1, a2, a3, a4, A, Z, N):\n",
    "    \n",
    "    return a0 + a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0)) \\\n",
    "            + a4*((N-Z)**2)/A\n",
    "\n",
    "def LiquidDropModel6d(params, A, Z, N):\n",
    "    \n",
    "    if len(params) == 5:\n",
    "        a0, a1, a2, a3, a4 = params\n",
    "        return a0 + a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0)) \\\n",
    "            + a4*((N-Z)**2)/A\n",
    "    else:\n",
    "        a0, a1, a2, a3, a4, a5 = params\n",
    "        return a0 + a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0)) \\\n",
    "            + a4*((N-Z)**2)/A + a5*( (-1)**Z + (-1)**N )*(0.5*A**(-0.5))\n",
    "\n",
    "    \n",
    "par = [5.8125,  0.15,    0.17,    0.0855, -0.295 ]\n",
    "LiquidDropModel6d(par, 1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70,)\n"
     ]
    }
   ],
   "source": [
    "# generate observational data with some uncertainty\n",
    "\n",
    "start = 30\n",
    "step = 3\n",
    "stop = 240\n",
    "\n",
    "obs_data = Energies[start:stop:step]\n",
    "sigma_obs = Energies_unc[start:stop:step]\n",
    "A = A0[start:stop:step]\n",
    "Z = Z0[start:stop:step]\n",
    "N = N0[start:stop:step]\n",
    "\n",
    "\n",
    "variables = np.concatenate((A.reshape(-1,1),Z.reshape(-1,1),\\\n",
    "                            N.reshape(-1,1)), axis=1)\n",
    "\n",
    "print(obs_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_var = [1, A, (A**(2.0/3.0)), Z*(Z-1)*(A**(-1.0/3.0)), \\\n",
    "                 ((N-Z)**2)/A, ( (-1)**Z + (-1)**N )*(0.5*A**(-0.5))]\n",
    "\n",
    "def design_matrix(ndim):\n",
    "    # design matrix X\n",
    "    X = np.zeros((len(A),ndim))\n",
    "    for i in range(ndim):\n",
    "        X[:,i] = indep_var[i]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.25757161e+00 -1.23776008e-01  5.84031989e-01  4.74106010e-03\n",
      "  1.58915921e-01  1.01318864e-01]\n",
      "[0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136\n",
      " 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136\n",
      " 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.072 0.072\n",
      " 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072\n",
      " 0.072 0.072 0.072 0.072 0.072 0.072 0.018 0.018 0.018 0.018 0.018 0.018\n",
      " 0.018 0.018 0.018 0.018 0.018 0.018 0.018 0.018 0.018 0.018]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = skl.LinearRegression(fit_intercept=False).fit(design_matrix(6), obs_data)\n",
    "\n",
    "print(clf.coef_)\n",
    "\n",
    "preds = clf.predict(design_matrix(6))\n",
    "\n",
    "\n",
    "err = np.sum(np.square(obs_data-preds))\n",
    "\n",
    "pred_sigma = np.sqrt(err / (len(obs_data) - 5)) \n",
    "\n",
    "#https://stats.stackexchange.com/questions/284772/estimator-of-variance-of-error\n",
    "#sigma_model = [3*pred_sigma,2*pred_sigma,pred_sigma]\n",
    "\n",
    "sigma_model  = np.zeros((len(A)))\n",
    "for i in range(len(A)):\n",
    "    if A[i] < 40:\n",
    "        sigma_model[i] = 0.997\n",
    "        \n",
    "    elif A[i] < 140:\n",
    "        sigma_model[i] = 0.136\n",
    "    elif A[i] < 200:\n",
    "        sigma_model[i] = 0.072\n",
    "    else:\n",
    "        sigma_model[i] = 0.018\n",
    "        \n",
    "print(sigma_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "volshapes = ['ellipsoid', 'hypercube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwaves = 5\n",
    "ndim = 6\n",
    "nsamples = 2 * (10**5)\n",
    "volshape = 'ellipsoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(historymatch)\n",
    "\n",
    "# initialise history matching class\n",
    "HM = historymatch.HistoryMatch(ndim, 'GP', volshape, nsamples=nsamples, ntraining=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples : 200000\n",
      "(200, 5)\n",
      "Running wave 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:53<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 8 ... 8 1 8]\n",
      "Number of Non-Implausible Samples : (17, 6)\n",
      "[[ 0.3982125 14.2933125]\n",
      " [-0.43463    0.51973  ]\n",
      " [-1.89201    1.88655  ]\n",
      " [-0.0397305  0.0379565]\n",
      " [-0.807385   0.840755 ]]\n",
      "Convergence : True\n",
      "Relative nonimplausible volume remaining: 0.067\n",
      "Running wave 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:09<00:00,  5.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 23 23 ... 23 18 23]\n",
      "Number of Non-Implausible Samples : (20246, 6)\n",
      "[[-7.69499055 19.77948038]\n",
      " [-1.09377717  0.82617676]\n",
      " [-3.2075965   4.47551856]\n",
      " [-0.06450918  0.06794961]\n",
      " [-1.80754484  2.21078931]]\n",
      "Convergence : True\n",
      "Relative nonimplausible volume remaining: 2.247\n",
      "Running wave 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [03:21<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35 39 39 ... 39 39 38]\n",
      "Number of Non-Implausible Samples : (21032, 6)\n",
      "[[-7.80303049 21.73528268]\n",
      " [-1.13673757  0.98954348]\n",
      " [-3.97627072  4.73887612]\n",
      " [-0.05813769  0.06136325]\n",
      " [-1.82995359  2.03532608]]\n",
      "Convergence : True\n",
      "Relative nonimplausible volume remaining: 2.634\n",
      "Running wave 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [06:04<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56 68 67 ... 69 63 67]\n",
      "Number of Non-Implausible Samples : (567, 6)\n",
      "[[ 1.19082473e+00  1.24064856e+01]\n",
      " [-3.62643707e-01  1.93113744e-01]\n",
      " [-8.79861553e-01  1.70986227e+00]\n",
      " [-9.61537576e-03  1.53836937e-02]\n",
      " [-3.30298228e-01  5.25988179e-01]]\n",
      "Convergence : True\n",
      "Relative nonimplausible volume remaining: 0.004\n",
      "Running wave 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [05:59<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63 69 68 ... 69 38 55]\n",
      "Number of Non-Implausible Samples : (77766, 6)\n",
      "[[-2.50093743e-02  1.42116634e+01]\n",
      " [-4.07322067e-01  2.73859347e-01]\n",
      " [-1.26757262e+00  1.94798700e+00]\n",
      " [-1.32254988e-02  1.71821787e-02]\n",
      " [-4.30811192e-01  6.16692890e-01]]\n",
      "Convergence : True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,5) (6,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-136c44527cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mHM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnwaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnwaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/historymatch.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nwaves)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mK0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonimplausible_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonimplausible_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0mtheta_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mellipsoid_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hypercube_rot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/sample.py\u001b[0m in \u001b[0;36mellipsoid_sample\u001b[0;34m(ndim, Nsamples, Ntraining, mean, covariance)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Add pertubation to covariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Calculate the Cholesky decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,5) (6,6) "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ToyModel = historymatch.Simulator(HM)\n",
    "ToyModel.set_simulator(LiquidDropModel6d)\n",
    "\n",
    "#obs_data[start:stop:step]\n",
    "\n",
    "HM.set_observations(obs_data, variables=variables, sigma_obs=sigma_obs, sigma_model=sigma_model, outputs_per_wave = [10,25,40])\n",
    "HM.initialize_volume(parameter_bounds[:,0], parameter_bounds[:,1])\n",
    "\n",
    "results = HM.run(nwaves=nwaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volshape2 = 'hypercube'\n",
    "#HM2 = historymatch.HistoryMatch(ndim, 'GP', volshape2, nsamples=nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToyModel2 = historymatch.Simulator(HM2)\n",
    "#ToyModel2.set_simulator(LiquidDropModel5d)\n",
    "\n",
    "#HM2.set_observations(obs_data, variables=variables, sigma_obs=sigma_obs, sigma_model=sigma_model, outputs_per_wave = [6])\n",
    "#HM2.initialize_volume(a_limits[:,0], a_limits[:,1])\n",
    "\n",
    "#results2 = HM2.run(nwaves=nwaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic_mean = np.loadtxt(\"data/6D_analytic_mean.txt\").reshape(ndim,)\n",
    "analytic_cov = np.loadtxt(\"data/6D_analytic_cov.txt\").reshape(ndim,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-03b196c41329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtheta_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mr'$a_{0}$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'$a_{V}$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'$a_{S}$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'$a_{C}$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'$a_{S}$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'$a_{P}$'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msample_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtempbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/utils.py\u001b[0m in \u001b[0;36mlocate_boundaries\u001b[0;34m(data, ndim)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfind_minmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfind_minmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Uni/Thesis/Code/HistoryMatching/historymatch/utils.py\u001b[0m in \u001b[0;36mfind_minmax\u001b[0;34m(data, i)\u001b[0m\n\u001b[1;32m     26\u001b[0m         '''\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfind_minmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfind_minmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "#importlib.reload(plot)\n",
    "\n",
    "colors = ['sandybrown', 'gold', 'yellowgreen', 'mediumseagreen', 'turquoise', 'cornflowerblue', 'mediumpurple', 'plum', 'lightpink', ]\n",
    "theta_names = [r'$a_{0}$', r'$a_{V}$', r'$a_{S}$', r'$a_{C}$', r'$a_{S}$', r'$a_{P}$']\n",
    "\n",
    "sample_bounds = utils.locate_boundaries(results.samples[-1], ndim)\n",
    "tempbounds = np.concatenate((sample_bounds[-1].reshape(-1,1),sample_bounds[-1].reshape(-1,1)),axis=1).T\n",
    "\n",
    "true = clf.coef_\n",
    "#true = [15.92808016, -18.53454643,  -0.72795844, -23.73239355,]\n",
    "\n",
    "fig, axes = plt.subplots(ndim, ndim, figsize=(15,15))\n",
    "if volshape == 'ellipsoid':\n",
    "    for k in range(nwaves):\n",
    "        \n",
    "        nonimplausible_scaled = np.zeros_like(results.nonimplausible[k])\n",
    "        for dim in range(ndim):\n",
    "            nonimplausible_scaled[:,dim] = results.nonimplausible[k][:,dim]\n",
    "        mean = np.mean(nonimplausible_scaled[:,:-1].T, axis=1)\n",
    "        cov = np.cov(nonimplausible_scaled[:,:-1].T)\n",
    "        if k < 5:\n",
    "            ndim = 5\n",
    "        else:\n",
    "            ndim = 6\n",
    "        for i in range(ndim):\n",
    "            for j in range(ndim):\n",
    "                ax = axes[j,i]\n",
    "                if i < j:\n",
    "                    #true_cov = np.array([[analytic_cov[i,i], analytic_cov[i,j]],[analytic_cov[j,i], analytic_cov[j,j]]])\n",
    "                    cov_matrix = np.array([[cov[i,i], cov[i,j]],[cov[j,i], cov[j,j]]])\n",
    "                    plot.get_cov_ellipse(cov_matrix, [mean[i],mean[j]], 3, 5.991, ax, colors[k])\n",
    "                    #plot.get_cov_ellipse(true_cov, [analytic_mean[i],analytic_mean[j]], 3, 5.991, ax, 'black')\n",
    "                    \n",
    "                    #ax.scatter(results.samples[1][:,i], results.samples[1][:,j], color=colors[4])\n",
    "                    #ax.scatter(results.nonimplausible[0][:,i], results.nonimplausible[0][:,j], color=colors[0])\n",
    "                    #ax.set_xlim([parameter_bounds[i][0],parameter_bounds[i][1]])\n",
    "                    #ax.set_ylim([parameter_bounds[j][0],parameter_bounds[j][1]])\n",
    "                    #ax.scatter(true[i],true[j])\n",
    "                    ax.set_xlabel(theta_names[i])\n",
    "                    ax.set_ylabel(theta_names[j])\n",
    "                elif i == j:\n",
    "                    #ax.plot(theta_vals[i], stats.norm.pdf(theta_vals[i], mean[i], np.sqrt(cov[i,i])), color='plum')\n",
    "                    ax.set_xlim([sample_bounds[i][0],sample_bounds[i][1]])\n",
    "                    #ax.set_title(str(theta_names[i]) + '=' + str(round(theta_best[i], 2)), fontsize=14)\n",
    "                else:\n",
    "                    ax.axis('off')\n",
    "elif volshape == 'hypercube':\n",
    "    for k in range(nwaves):\n",
    "        nonimplausible = np.zeros_like(results.nonimp_bounds[k])\n",
    "        for dim in range(ndim):\n",
    "            nonimplausible[dim] = results.nonimp_bounds[k][dim]\n",
    "            \n",
    "        for i in range(ndim):\n",
    "            for j in range(ndim):\n",
    "                ax = axes[j,i]\n",
    "                if i < j:\n",
    "                    true_cov = np.array([[analytic_cov[i,i], analytic_cov[i,j]],[analytic_cov[j,i], analytic_cov[j,j]]])\n",
    "                    ax.add_patch(Rectangle((nonimplausible[i,0], nonimplausible[j,0]),\\\n",
    "                                           (nonimplausible[i,1]-nonimplausible[i,0]), \\\n",
    "                                           (nonimplausible[j,1]-nonimplausible[j,0]),\\\n",
    "                        color=colors[k],alpha=0.7,label='Nonimp. Hypercube'))\n",
    "                    plot.get_cov_ellipse(true_cov, [analytic_mean[i],analytic_mean[j]], 3, 5.991, ax, 'black')\n",
    "                    ax.set_xlim([parameter_bounds[i][0],parameter_bounds[i][1]])\n",
    "                    ax.set_ylim([parameter_bounds[j][0],parameter_bounds[j][1]])\n",
    "                    ax.set_xlabel(theta_names[i])\n",
    "                    ax.set_ylabel(theta_names[j])\n",
    "                else:\n",
    "                    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "#ax.scatter(samples_scaled[:,0], samples_scaled[:,1], samples_scaled[:,2], s=10, color='gold', alpha=0.1, label='Nonimplausible Samples')\n",
    "ax.scatter(nonimplausible_scaled[:,0], nonimplausible_scaled[:,1], nonimplausible_scaled[:,2], s=20, color='red', label='Nonimplausible Samples')\n",
    "ax.scatter(true[0],true[1],true[2])\n",
    "#ax.view_init(0, 90)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'Nsamples : ' : len(results.samples[0]), 'Noutputs : ' : len(obs_data), 'Output First : ' : start, 'Output Last : ' : stop}\n",
    "\n",
    "keys = np.array(['Nsamples', 'Noutputs', 'StartZ', 'EndZ']).reshape(1,-1)\n",
    "vals = np.array([len(results.samples[0]), len(obs_data), start, stop]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''shape = volshape\n",
    "for wave in range(nwaves):\n",
    "    file = open(\"data/{}D_HM_w{}_{}_nonimp_noem.txt\".format(ndim,wave,shape), \"w\")\n",
    "    np.savetxt(file, results.nonimplausible[wave])\n",
    "    file.close()\n",
    "    file3 = open(\"data/{}D_HM_w{}_{}_samples_noem.txt\".format(ndim,wave,shape), \"w\")\n",
    "    np.savetxt(file3, results.I_samples[wave])\n",
    "    file3.close()\n",
    "    file2 = open(\"data/{}D_HM_details_{}_noem.txt\".format(ndim,wave,shape), \"w\")\n",
    "    np.savetxt(file2, keys, fmt=\"%s\")\n",
    "    np.savetxt(file2, vals, fmt=\"%d\")\n",
    "    file2.close()'''\n",
    "    '''else:\n",
    "        for wave in range(nwaves):\n",
    "            file = open(\"data/{}D_HM_w{}_{}_nonimp.txt\".format(ndim,wave,shape), \"w\")\n",
    "            np.savetxt(file, results2.nonimplausible[wave])\n",
    "            file.close()\n",
    "            file3 = open(\"data/{}D_HM_w{}_{}_samples.txt\".format(ndim,wave,shape), \"w\")\n",
    "            np.savetxt(file3, results2.I_samples[wave])\n",
    "            file3.close()\n",
    "            file2 = open(\"data/{}D_HM_details_{}.txt\".format(ndim,wave,shape), \"w\")\n",
    "            np.savetxt(file2, keys, fmt=\"%s\")\n",
    "            np.savetxt(file2, vals, fmt=\"%d\")\n",
    "            file2.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
