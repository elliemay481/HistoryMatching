{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal files\n",
    "from historymatch import emulators\n",
    "from historymatch import sample\n",
    "from historymatch import historymatch\n",
    "from historymatch import plot\n",
    "from historymatch import utils\n",
    "\n",
    "\n",
    "# import external modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import pandas as pd\n",
    "#import importlib\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import sklearn.linear_model as skl\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "np.random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "with open(\"data/MassEval2016.dat\",'r') as infile:\n",
    "    Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11,12),\n",
    "              names=('N', 'Z', 'A', 'Element', 'Ebinding', 'E_unc'),\n",
    "              widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\n",
    "              header=64,\n",
    "              index_col=False)\n",
    "    \n",
    "# Extrapolated values are indicated by '#' in place of the decimal place, so\n",
    "# the Ebinding column won't be numeric. Coerce to float and drop these entries.\n",
    "Masses['Ebinding'] = pd.to_numeric(Masses['Ebinding'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "Masses['E_unc'] = pd.to_numeric(Masses['E_unc'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "# Convert from keV to MeV.\n",
    "Masses['Ebinding'] /= 1000\n",
    "Masses['E_unc'] /= 1000\n",
    "\n",
    "# Group the DataFrame by nucleon number, A.\n",
    "Masses = Masses.groupby('A')\n",
    "# Find the rows of the grouped DataFrame with the maximum binding energy.\n",
    "Masses = Masses.apply(lambda t: t[t.Ebinding==t.Ebinding.max()])\n",
    "\n",
    "A0 = Masses['A'].to_numpy()\n",
    "Z0 = Masses['Z'].to_numpy()\n",
    "N0 = Masses['N'].to_numpy()\n",
    "Element = Masses['Element'].to_numpy()\n",
    "Energies = Masses['Ebinding'].to_numpy()\n",
    "\n",
    "#Energies_unc = Masses['E_unc'].to_numpy()\n",
    "Energies_unc = Masses['E_unc'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space\n",
    "\n",
    "\n",
    "a0_lim = np.array([4,8]).reshape(1,-1)\n",
    "a1_lim = np.array([0, 1.1]).reshape(1,-1)\n",
    "a2_lim = np.array([-0.4, 0.1]).reshape(1,-1)\n",
    "a3_lim = np.array([-0.01, 0.015]).reshape(1,-1)\n",
    "a4_lim = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "a5_lim = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "\n",
    "#[ 5.73205069 -0.15849126  0.73057298  0.00661303  0.21505478  0.12058198]\n",
    "\n",
    "a_limits = np.concatenate((a0_lim, a1_lim, \\\n",
    "                            a2_lim, a3_lim, a4_lim, a5_lim), axis=0)\n",
    "\n",
    "theta_0_vals = np.linspace(a_limits[0,0], a_limits[0,1], 100)\n",
    "theta_1_vals = np.linspace(a_limits[1,0], a_limits[1,1], 100)\n",
    "theta_2_vals = np.linspace(a_limits[2,0], a_limits[2,1], 100)\n",
    "\n",
    "theta_0_bound = np.array([4, 8]).reshape(1,-1)\n",
    "theta_1_bound = np.array([-0.4, 0]).reshape(1,-1)\n",
    "theta_2_bound = np.array([0.4, 0.7]).reshape(1,-1)\n",
    "theta_3_bound = np.array([-0.005, 0.015]).reshape(1,-1) # keep\n",
    "theta_4_bound = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "theta_5_bound = np.array([-0.1, 0.4]).reshape(1,-1)\n",
    "\n",
    "\n",
    "parameter_bounds = np.concatenate((theta_0_bound, theta_1_bound, \\\n",
    "                                   theta_2_bound, theta_3_bound, theta_4_bound, theta_5_bound), axis=0)\n",
    "\n",
    "\n",
    "theta_vals = np.concatenate((theta_0_vals.reshape(1,-1), theta_1_vals.reshape(1,-1), theta_2_vals.reshape(1,-1)), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LiquidDropModel4d(a0, a1, a2, a3, A, Z, N):\n",
    "    \n",
    "    return a0 + a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0))\n",
    "\n",
    "def LiquidDropModel5d(a0, a1, a2, a3, a4, A, Z, N):\n",
    "    \n",
    "    return a0 + a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0)) \\\n",
    "            + a4*((N-Z)**2)/A\n",
    "\n",
    "def LiquidDropModel6d(a0, a1, a2, a3, a4, a5, A, Z, N):\n",
    "    \n",
    "    return a0 + a1*A + a2*(A**(2.0/3.0)) + a3*Z*(Z-1)*(A**(-1.0/3.0)) \\\n",
    "            + a4*((N-Z)**2)/A + a5*( (-1)**Z + (-1)**N )*(0.5*A**(-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53,)\n"
     ]
    }
   ],
   "source": [
    "# generate observational data with some uncertainty\n",
    "\n",
    "start = 30\n",
    "step = 4\n",
    "stop = 240\n",
    "\n",
    "obs_data = Energies[start:stop:step]\n",
    "sigma_obs = Energies_unc[start:stop:step]\n",
    "A = A0[start:stop:step]\n",
    "Z = Z0[start:stop:step]\n",
    "N = N0[start:stop:step]\n",
    "\n",
    "\n",
    "variables = np.concatenate((A.reshape(-1,1),Z.reshape(-1,1),\\\n",
    "                            N.reshape(-1,1)), axis=1)\n",
    "\n",
    "print(obs_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_var = [1, A, (A**(2.0/3.0)), Z*(Z-1)*(A**(-1.0/3.0)), \\\n",
    "                 ((N-Z)**2)/A, ( (-1)**Z + (-1)**N )*(0.5*A**(-0.5))]\n",
    "\n",
    "def design_matrix(ndim):\n",
    "    # design matrix X\n",
    "    X = np.zeros((len(A),ndim))\n",
    "    for i in range(ndim):\n",
    "        X[:,i] = indep_var[i]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.89559726e+01  1.19549026e-01 -7.78119950e-01 -4.41062300e-03\n",
      " -1.38660497e-01 -3.52781654e+01]\n",
      "[0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136\n",
      " 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136 0.136\n",
      " 0.136 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072 0.072\n",
      " 0.072 0.072 0.072 0.072 0.018 0.018 0.018 0.018 0.018 0.018 0.018 0.018\n",
      " 0.018 0.018 0.018 0.018 0.018]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = skl.LinearRegression(fit_intercept=False).fit(design_matrix(6), obs_data)\n",
    "\n",
    "print(clf.coef_)\n",
    "\n",
    "preds = clf.predict(design_matrix(6))\n",
    "\n",
    "\n",
    "err = np.sum(np.square(obs_data-preds))\n",
    "\n",
    "pred_sigma = np.sqrt(err / (len(obs_data) - 5)) \n",
    "\n",
    "#https://stats.stackexchange.com/questions/284772/estimator-of-variance-of-error\n",
    "#sigma_model = [3*pred_sigma,2*pred_sigma,pred_sigma]\n",
    "\n",
    "sigma_model  = np.zeros((len(A)))\n",
    "for i in range(len(A)):\n",
    "    if A[i] < 40:\n",
    "        sigma_model[i] = 0.997\n",
    "        \n",
    "    elif A[i] < 140:\n",
    "        sigma_model[i] = 0.136\n",
    "    elif A[i] < 200:\n",
    "        sigma_model[i] = 0.072\n",
    "    else:\n",
    "        sigma_model[i] = 0.018\n",
    "        \n",
    "print(sigma_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "volshapes = ['ellipsoid', 'hypercube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwaves = 5\n",
    "ndim = 6\n",
    "nsamples = 2 * (10**6)\n",
    "volshape = 'hypercube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(historymatch)\n",
    "\n",
    "# initialise history matching class\n",
    "HM = historymatch.HistoryMatch(ndim, 'GP', volshape, nsamples=nsamples, ntraining=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples : 2000000\n",
      "(1500, 6)\n",
      "Running wave 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ToyModel = historymatch.Simulator(HM)\n",
    "ToyModel.set_simulator(LiquidDropModel6d)\n",
    "\n",
    "#obs_data[start:stop:step]\n",
    "\n",
    "HM.set_observations(obs_data, variables=variables, sigma_obs=sigma_obs, sigma_model=sigma_model, outputs_per_wave = [10,25,40])\n",
    "HM.initialize_volume(parameter_bounds[:,0], parameter_bounds[:,1])\n",
    "\n",
    "results = HM.run(nwaves=nwaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volshape2 = 'hypercube'\n",
    "#HM2 = historymatch.HistoryMatch(ndim, 'GP', volshape2, nsamples=nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToyModel2 = historymatch.Simulator(HM2)\n",
    "#ToyModel2.set_simulator(LiquidDropModel5d)\n",
    "\n",
    "#HM2.set_observations(obs_data, variables=variables, sigma_obs=sigma_obs, sigma_model=sigma_model, outputs_per_wave = [6])\n",
    "#HM2.initialize_volume(a_limits[:,0], a_limits[:,1])\n",
    "\n",
    "#results2 = HM2.run(nwaves=nwaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic_mean = np.loadtxt(\"data/6D_analytic_mean.txt\").reshape(ndim,)\n",
    "analytic_cov = np.loadtxt(\"data/6D_analytic_cov.txt\").reshape(ndim,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(plot)\n",
    "\n",
    "colors = ['sandybrown', 'gold', 'yellowgreen', 'mediumseagreen', 'turquoise', 'cornflowerblue', 'mediumpurple', 'plum', 'lightpink', ]\n",
    "theta_names = [r'$a_{0}$', r'$a_{V}$', r'$a_{S}$', r'$a_{C}$', r'$a_{S}$', r'$a_{P}$']\n",
    "\n",
    "sample_bounds = utils.locate_boundaries(results.samples[-1], ndim)\n",
    "tempbounds = np.concatenate((sample_bounds[-1].reshape(-1,1),sample_bounds[-1].reshape(-1,1)),axis=1).T\n",
    "\n",
    "true = clf.coef_\n",
    "#true = [15.92808016, -18.53454643,  -0.72795844, -23.73239355,]\n",
    "\n",
    "fig, axes = plt.subplots(ndim, ndim, figsize=(15,15))\n",
    "if volshape == 'ellipsoid':\n",
    "    for k in range(nwaves):\n",
    "        \n",
    "        nonimplausible_scaled = np.zeros_like(results.nonimplausible[k])\n",
    "        for dim in range(ndim):\n",
    "            nonimplausible_scaled[:,dim] = results.nonimplausible[k][:,dim]\n",
    "        mean = np.mean(nonimplausible_scaled[:,:-1].T, axis=1)\n",
    "        cov = np.cov(nonimplausible_scaled[:,:-1].T)\n",
    "        \n",
    "        for i in range(ndim):\n",
    "            for j in range(ndim):\n",
    "                ax = axes[j,i]\n",
    "                if i < j:\n",
    "                    true_cov = np.array([[analytic_cov[i,i], analytic_cov[i,j]],[analytic_cov[j,i], analytic_cov[j,j]]])\n",
    "                    cov_matrix = np.array([[cov[i,i], cov[i,j]],[cov[j,i], cov[j,j]]])\n",
    "                    plot.get_cov_ellipse(cov_matrix, [mean[i],mean[j]], 3, 5.991, ax, colors[k])\n",
    "                    plot.get_cov_ellipse(true_cov, [analytic_mean[i],analytic_mean[j]], 3, 5.991, ax, 'black')\n",
    "                    \n",
    "                    #ax.scatter(results.samples[1][:,i], results.samples[1][:,j], color=colors[4])\n",
    "                    #ax.scatter(results.nonimplausible[0][:,i], results.nonimplausible[0][:,j], color=colors[0])\n",
    "                    #ax.set_xlim([parameter_bounds[i][0],parameter_bounds[i][1]])\n",
    "                    #ax.set_ylim([parameter_bounds[j][0],parameter_bounds[j][1]])\n",
    "                    #ax.scatter(true[i],true[j])\n",
    "                    ax.set_xlabel(theta_names[i])\n",
    "                    ax.set_ylabel(theta_names[j])\n",
    "                elif i == j:\n",
    "                    #ax.plot(theta_vals[i], stats.norm.pdf(theta_vals[i], mean[i], np.sqrt(cov[i,i])), color='plum')\n",
    "                    ax.set_xlim([sample_bounds[i][0],sample_bounds[i][1]])\n",
    "                    #ax.set_title(str(theta_names[i]) + '=' + str(round(theta_best[i], 2)), fontsize=14)\n",
    "                else:\n",
    "                    ax.axis('off')\n",
    "elif volshape == 'hypercube':\n",
    "    for k in range(nwaves):\n",
    "        nonimplausible = np.zeros_like(results.nonimp_bounds[k])\n",
    "        for dim in range(ndim):\n",
    "            nonimplausible[dim] = results.nonimp_bounds[k][dim]\n",
    "            \n",
    "        for i in range(ndim):\n",
    "            for j in range(ndim):\n",
    "                ax = axes[j,i]\n",
    "                if i < j:\n",
    "                    true_cov = np.array([[analytic_cov[i,i], analytic_cov[i,j]],[analytic_cov[j,i], analytic_cov[j,j]]])\n",
    "                    ax.add_patch(Rectangle((nonimplausible[i,0], nonimplausible[j,0]),\\\n",
    "                                           (nonimplausible[i,1]-nonimplausible[i,0]), \\\n",
    "                                           (nonimplausible[j,1]-nonimplausible[j,0]),\\\n",
    "                        color=colors[k],alpha=0.7,label='Nonimp. Hypercube'))\n",
    "                    plot.get_cov_ellipse(true_cov, [analytic_mean[i],analytic_mean[j]], 3, 5.991, ax, 'black')\n",
    "                    ax.set_xlim([parameter_bounds[i][0],parameter_bounds[i][1]])\n",
    "                    ax.set_ylim([parameter_bounds[j][0],parameter_bounds[j][1]])\n",
    "                    ax.set_xlabel(theta_names[i])\n",
    "                    ax.set_ylabel(theta_names[j])\n",
    "                else:\n",
    "                    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "#ax.scatter(samples_scaled[:,0], samples_scaled[:,1], samples_scaled[:,2], s=10, color='gold', alpha=0.1, label='Nonimplausible Samples')\n",
    "ax.scatter(nonimplausible_scaled[:,0], nonimplausible_scaled[:,1], nonimplausible_scaled[:,2], s=20, color='red', label='Nonimplausible Samples')\n",
    "ax.scatter(true[0],true[1],true[2])\n",
    "#ax.view_init(0, 90)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'Nsamples : ' : len(results.samples[0]), 'Noutputs : ' : len(obs_data), 'Output First : ' : start, 'Output Last : ' : stop}\n",
    "\n",
    "keys = np.array(['Nsamples', 'Noutputs', 'StartZ', 'EndZ']).reshape(1,-1)\n",
    "vals = np.array([len(results.samples[0]), len(obs_data), start, stop]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = volshape\n",
    "for wave in range(nwaves):\n",
    "    file = open(\"data/{}D_HM_w{}_{}_nonimp_noem.txt\".format(ndim,wave,shape), \"w\")\n",
    "    np.savetxt(file, results.nonimplausible[wave])\n",
    "    file.close()\n",
    "    file3 = open(\"data/{}D_HM_w{}_{}_samples_noem.txt\".format(ndim,wave,shape), \"w\")\n",
    "    np.savetxt(file3, results.I_samples[wave])\n",
    "    file3.close()\n",
    "    file2 = open(\"data/{}D_HM_details_{}_noem.txt\".format(ndim,wave,shape), \"w\")\n",
    "    np.savetxt(file2, keys, fmt=\"%s\")\n",
    "    np.savetxt(file2, vals, fmt=\"%d\")\n",
    "    file2.close()\n",
    "    '''else:\n",
    "        for wave in range(nwaves):\n",
    "            file = open(\"data/{}D_HM_w{}_{}_nonimp.txt\".format(ndim,wave,shape), \"w\")\n",
    "            np.savetxt(file, results2.nonimplausible[wave])\n",
    "            file.close()\n",
    "            file3 = open(\"data/{}D_HM_w{}_{}_samples.txt\".format(ndim,wave,shape), \"w\")\n",
    "            np.savetxt(file3, results2.I_samples[wave])\n",
    "            file3.close()\n",
    "            file2 = open(\"data/{}D_HM_details_{}.txt\".format(ndim,wave,shape), \"w\")\n",
    "            np.savetxt(file2, keys, fmt=\"%s\")\n",
    "            np.savetxt(file2, vals, fmt=\"%d\")\n",
    "            file2.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
